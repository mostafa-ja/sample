{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4ghudCNos9HAFyVCdFW8N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/sample/blob/master/Emojify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rufFNufqDmUO"
      },
      "source": [
        "# Emotion detection from text using PyTorch and Federated Learning\n",
        "\n",
        "For this project, we are going to implement an NLP task of creating a model to detect the emotion from text. We will develop this using the PyTorch library and the Federated Learning framework for decentralized training. \n",
        "\n",
        "We will create an emotion detection for the following 5 emotions:\n",
        "\n",
        "| Emotion | Emoji   | Label   |\n",
        "|------|------|------|\n",
        "|Loving| ‚ù§Ô∏è| 0|\n",
        "|Playful| ‚öΩÔ∏è| 1|\n",
        "|Happy| üòÑ| 2|\n",
        "|Annoyed| üòû| 3|\n",
        "|Foodie| üçΩ| 4|\n",
        "\n",
        "## Dataset\n",
        "\n",
        "We will work with a dataset (X, Y) where we have:\n",
        "*   X contains 132 sentences\n",
        "*   Y contains a label between [0, 4] corresponding to the five emotions.\n",
        "\n",
        "For example:\n",
        "\n",
        "| Sentence | Emotion   |\n",
        "|----------|-----------|\n",
        "|food is life|  üçΩ Foodie|\n",
        "|I love you mum|  ‚ù§Ô∏è Loving|\n",
        "|Stop saying bullshit|  üòû Annoyed|\n",
        "|congratulations on your acceptance|  üòÑ Happy|\n",
        "|The assignment is too long|    üòû Annoyed|\n",
        "|I want to go play| ‚öΩÔ∏è Playful|\n",
        "|she did not answer my text| üòû Annoyed|\n",
        "|Your stupidity has no limit| üòû Annoyed|\n",
        "|how many points did he score|  ‚öΩÔ∏è Playful|\n",
        "|my algorithm performs poorly| üòû Annoyed|\n",
        "|I got approved|  üòÑ Happy|\n",
        "\n",
        "## The Model\n",
        "We will build an LSTM model that takes as input word sequences that will take word ordering into account. We will use 50-dimensional [GloVe](https://nlp.stanford.edu/projects/glove/) pre-trained word embeddings to represent words. We will then feed those as an input into an LSTM that will predict the most appropiate emotion for the text. \n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1s-KYhU5JWF-jvAlZ2MIKKugxLLDdhpQP)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/coursera-deep-learning-specialization/master/C5%20-%20Sequence%20Models/Week%202/Emojify/data/train_emoji.csv'\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/coursera-deep-learning-specialization/master/C5%20-%20Sequence%20Models/Week%202/Emojify/data/test_emoji.csv'\n",
        "!wget 'https://ia803006.us.archive.org/1/items/glove.6B.50d-300d/glove.6B.50d.txt'\n"
      ],
      "metadata": {
        "id": "sLzJ34ArHM1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQn1wO2qr01C"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d04n5XXyf5Cj"
      },
      "source": [
        "# HELPER FUNCTIONS\n",
        "\n",
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)]\n",
        "    return Y\n",
        "\n",
        "def read_csv(filename):\n",
        "    phrase = []\n",
        "    emoji = []\n",
        "\n",
        "    with open (filename) as csvDataFile:\n",
        "        csvReader = csv.reader(csvDataFile)\n",
        "\n",
        "        for row in csvReader:\n",
        "            phrase.append(row[0])\n",
        "            emoji.append(row[1])\n",
        "\n",
        "    X = np.asarray(phrase)\n",
        "    Y = np.asarray(emoji, dtype=int)\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = read_csv('/content/train_emoji.csv')\n",
        "X_test, Y_test = read_csv('/content/test_emoji.csv')"
      ],
      "metadata": {
        "id": "XAdaQ1i1IxXx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtWINKCgI8ud",
        "outputId": "6958c4c5-2b16-4254-ca00-912a542cef19"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(132,) (132,)\n",
            "(56,) (56,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0],Y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czbmBGHOJKyM",
        "outputId": "86b0d0f2-ab22-41a0-f930-d5ea944db55f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "never talk to me again 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.eye(5)[0])\n",
        "print(np.eye(5)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp7J62vdJ3jD",
        "outputId": "4e5960f1-cda7-42e1-b07a-8f873a3bef6f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_oh_train = np.eye(5)[Y_train]\n",
        "Y_oh_test = np.eye(5)[Y_test]\n",
        "print(Y_oh_train.shape)\n",
        "print(Y_oh_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjQfqekeJanm",
        "outputId": "6ae271e5-cc76-4906-fe1c-b6c65ae8600a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(132, 5)\n",
            "(56, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g_rSgh1iKU83"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}