{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Tutorial 16 - How To Use The TensorBoard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3UIspU6y1+cwXDCekEIlJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/sample/blob/master/PyTorch_Tutorial_16_How_To_Use_The_TensorBoard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Youtube link](https://www.youtube.com/watch?v=VJW9wU-1n18&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=16)"
      ],
      "metadata": {
        "id": "a_HQT3UjVEY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "tXxmclIJVxfm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "0bVnUsgzVNGY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter('runs/mnist1')"
      ],
      "metadata": {
        "id": "xy0reNjcWLSa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "w26HFx0DWvem"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameters\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "batch_size = 4\n",
        "num_epochs = 1\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "6lxOfhP8XKzl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "MGAiXzJtVjbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                                 torchvision.transforms.Normalize([0.1307,], [0.3081,])]) # just one element because of shape (1, 28, 28)"
      ],
      "metadata": {
        "id": "EtBKjk5mYxAb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset \n",
        "train_dataset = torchvision.datasets.MNIST('/content/data',train=True, transform=data_transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST('/content/data',train=False, transform=data_transform, download=True)\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "s0Rc3pEpVa1B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# samples\n",
        "\n",
        "example_data,example_label = next(iter(train_loader))\n",
        "img_grid = torchvision.utils.make_grid(example_data)\n",
        "\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_image('samples',img_grid)\n",
        "\n",
        "# writer.close()\n",
        "# %tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "WXBUuMHwaoWC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(example_data.shape)\n",
        "print(img_grid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdN3fwcedrPV",
        "outputId": "7ec8b74e-4cc8-469a-f2eb-481b38c243f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1, 28, 28])\n",
            "torch.Size([3, 32, 122])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_size,hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    # no activation and no softmax at the end\n",
        "    return out"
      ],
      "metadata": {
        "id": "Z_kGFuxEfmE6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(input_size,hidden_size,num_classes).to(device)   # Set the model to run on the GPU.\n",
        "\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_graph(model,example_data.reshape(-1,28*28).to(device))  # ATTENTION : must do .to(device) for example_data\n",
        "\n",
        "# writer.close()\n",
        "# %tensorboard --logdir=runs\n"
      ],
      "metadata": {
        "id": "Lq1ME2KuhW2f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "2iFj3cSL24Fd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "33Itj1jXpfOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f'Epoch {epoch+1}/{num_epochs} ')\n",
        "  print('_ _ ' * 10)\n",
        "\n",
        "  for i,(images,labels) in enumerate(train_loader):\n",
        "    # origin shape: [batch_s, 1, 28, 28] , resized: [100, 784]\n",
        "    images = images.reshape(-1,28*28).to(device)\n",
        "    labels = labels.to(device) # # Set the data to run on the GPU.\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs,labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()     # OR running_loss += loss.item()* images.size(0)   :  images.size(0) == images.shape[0] == batch_size\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)                   # ATTENTION: output.data is like loss.item() remove grad graph from data,\n",
        "                                                                # but we cant use item() beacuse the result is not one element tensor\n",
        "    running_correct += (labels==predicted).sum().item()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(f'Step {i+1}/{n_total_steps} , Loss : {loss.item():.4f}  ')\n",
        "\n",
        "      ############## TENSORBOARD ########################\n",
        "      writer.add_scalar(tag='training loss', scalar_value= running_loss/100, global_step= n_total_steps * epoch + i)\n",
        "      running_accuracy = (running_correct / 100) / predicted.size(0)  # predicted.size(0) == predicted.shape[0]\n",
        "      writer.add_scalar('accuracy', running_accuracy, global_step= n_total_steps * epoch + i)\n",
        "      running_loss = 0.0\n",
        "      running_correct = 0\n",
        "      ###################################################\n",
        "    "
      ],
      "metadata": {
        "id": "r6AVg8H1pe_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ab64e5-345b-42b4-9afc-1156da5dec33"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 \n",
            "__________\n",
            "Step 100/15000 , Loss : 0.6008  \n",
            "Step 200/15000 , Loss : 0.5181  \n",
            "Step 300/15000 , Loss : 0.1389  \n",
            "Step 400/15000 , Loss : 0.1191  \n",
            "Step 500/15000 , Loss : 0.1029  \n",
            "Step 600/15000 , Loss : 0.0095  \n",
            "Step 700/15000 , Loss : 0.8239  \n",
            "Step 800/15000 , Loss : 0.5510  \n",
            "Step 900/15000 , Loss : 0.0842  \n",
            "Step 1000/15000 , Loss : 0.8247  \n",
            "Step 1100/15000 , Loss : 0.3234  \n",
            "Step 1200/15000 , Loss : 0.0070  \n",
            "Step 1300/15000 , Loss : 0.0019  \n",
            "Step 1400/15000 , Loss : 0.1068  \n",
            "Step 1500/15000 , Loss : 0.3971  \n",
            "Step 1600/15000 , Loss : 0.3709  \n",
            "Step 1700/15000 , Loss : 0.0131  \n",
            "Step 1800/15000 , Loss : 0.0693  \n",
            "Step 1900/15000 , Loss : 0.1984  \n",
            "Step 2000/15000 , Loss : 0.0167  \n",
            "Step 2100/15000 , Loss : 0.0883  \n",
            "Step 2200/15000 , Loss : 0.0158  \n",
            "Step 2300/15000 , Loss : 0.0005  \n",
            "Step 2400/15000 , Loss : 0.0642  \n",
            "Step 2500/15000 , Loss : 0.0785  \n",
            "Step 2600/15000 , Loss : 0.0123  \n",
            "Step 2700/15000 , Loss : 0.4944  \n",
            "Step 2800/15000 , Loss : 0.0345  \n",
            "Step 2900/15000 , Loss : 1.3620  \n",
            "Step 3000/15000 , Loss : 0.0015  \n",
            "Step 3100/15000 , Loss : 0.0154  \n",
            "Step 3200/15000 , Loss : 0.9504  \n",
            "Step 3300/15000 , Loss : 1.0025  \n",
            "Step 3400/15000 , Loss : 0.2656  \n",
            "Step 3500/15000 , Loss : 0.0385  \n",
            "Step 3600/15000 , Loss : 0.0083  \n",
            "Step 3700/15000 , Loss : 0.0030  \n",
            "Step 3800/15000 , Loss : 0.0121  \n",
            "Step 3900/15000 , Loss : 0.0052  \n",
            "Step 4000/15000 , Loss : 0.9187  \n",
            "Step 4100/15000 , Loss : 0.0059  \n",
            "Step 4200/15000 , Loss : 0.0014  \n",
            "Step 4300/15000 , Loss : 0.0247  \n",
            "Step 4400/15000 , Loss : 0.2168  \n",
            "Step 4500/15000 , Loss : 0.1118  \n",
            "Step 4600/15000 , Loss : 0.1835  \n",
            "Step 4700/15000 , Loss : 0.1556  \n",
            "Step 4800/15000 , Loss : 0.2611  \n",
            "Step 4900/15000 , Loss : 0.0220  \n",
            "Step 5000/15000 , Loss : 0.0217  \n",
            "Step 5100/15000 , Loss : 0.1376  \n",
            "Step 5200/15000 , Loss : 0.0389  \n",
            "Step 5300/15000 , Loss : 0.3546  \n",
            "Step 5400/15000 , Loss : 0.0065  \n",
            "Step 5500/15000 , Loss : 0.0551  \n",
            "Step 5600/15000 , Loss : 0.3572  \n",
            "Step 5700/15000 , Loss : 0.0463  \n",
            "Step 5800/15000 , Loss : 0.0081  \n",
            "Step 5900/15000 , Loss : 0.0215  \n",
            "Step 6000/15000 , Loss : 0.0135  \n",
            "Step 6100/15000 , Loss : 0.0000  \n",
            "Step 6200/15000 , Loss : 0.0176  \n",
            "Step 6300/15000 , Loss : 0.0011  \n",
            "Step 6400/15000 , Loss : 0.0618  \n",
            "Step 6500/15000 , Loss : 0.6478  \n",
            "Step 6600/15000 , Loss : 2.0895  \n",
            "Step 6700/15000 , Loss : 0.2225  \n",
            "Step 6800/15000 , Loss : 0.0003  \n",
            "Step 6900/15000 , Loss : 0.0342  \n",
            "Step 7000/15000 , Loss : 0.0069  \n",
            "Step 7100/15000 , Loss : 0.0107  \n",
            "Step 7200/15000 , Loss : 0.7346  \n",
            "Step 7300/15000 , Loss : 0.0825  \n",
            "Step 7400/15000 , Loss : 0.2652  \n",
            "Step 7500/15000 , Loss : 0.0359  \n",
            "Step 7600/15000 , Loss : 0.2714  \n",
            "Step 7700/15000 , Loss : 0.0039  \n",
            "Step 7800/15000 , Loss : 0.6166  \n",
            "Step 7900/15000 , Loss : 0.0742  \n",
            "Step 8000/15000 , Loss : 0.0016  \n",
            "Step 8100/15000 , Loss : 0.0120  \n",
            "Step 8200/15000 , Loss : 0.0010  \n",
            "Step 8300/15000 , Loss : 0.0001  \n",
            "Step 8400/15000 , Loss : 1.6958  \n",
            "Step 8500/15000 , Loss : 0.3822  \n",
            "Step 8600/15000 , Loss : 0.0053  \n",
            "Step 8700/15000 , Loss : 0.0323  \n",
            "Step 8800/15000 , Loss : 0.0647  \n",
            "Step 8900/15000 , Loss : 0.0021  \n",
            "Step 9000/15000 , Loss : 0.0369  \n",
            "Step 9100/15000 , Loss : 0.0004  \n",
            "Step 9200/15000 , Loss : 0.1987  \n",
            "Step 9300/15000 , Loss : 0.0008  \n",
            "Step 9400/15000 , Loss : 1.8350  \n",
            "Step 9500/15000 , Loss : 0.0804  \n",
            "Step 9600/15000 , Loss : 0.0031  \n",
            "Step 9700/15000 , Loss : 0.0000  \n",
            "Step 9800/15000 , Loss : 0.0050  \n",
            "Step 9900/15000 , Loss : 0.0003  \n",
            "Step 10000/15000 , Loss : 0.2811  \n",
            "Step 10100/15000 , Loss : 0.0010  \n",
            "Step 10200/15000 , Loss : 0.6078  \n",
            "Step 10300/15000 , Loss : 0.0023  \n",
            "Step 10400/15000 , Loss : 0.0023  \n",
            "Step 10500/15000 , Loss : 0.0000  \n",
            "Step 10600/15000 , Loss : 0.0007  \n",
            "Step 10700/15000 , Loss : 0.1399  \n",
            "Step 10800/15000 , Loss : 0.0003  \n",
            "Step 10900/15000 , Loss : 0.0631  \n",
            "Step 11000/15000 , Loss : 0.0534  \n",
            "Step 11100/15000 , Loss : 0.0019  \n",
            "Step 11200/15000 , Loss : 0.1511  \n",
            "Step 11300/15000 , Loss : 0.0016  \n",
            "Step 11400/15000 , Loss : 0.0191  \n",
            "Step 11500/15000 , Loss : 0.0010  \n",
            "Step 11600/15000 , Loss : 0.0007  \n",
            "Step 11700/15000 , Loss : 0.0840  \n",
            "Step 11800/15000 , Loss : 0.0104  \n",
            "Step 11900/15000 , Loss : 0.0019  \n",
            "Step 12000/15000 , Loss : 0.0010  \n",
            "Step 12100/15000 , Loss : 0.0000  \n",
            "Step 12200/15000 , Loss : 0.0000  \n",
            "Step 12300/15000 , Loss : 0.0076  \n",
            "Step 12400/15000 , Loss : 0.2675  \n",
            "Step 12500/15000 , Loss : 0.9016  \n",
            "Step 12600/15000 , Loss : 0.0018  \n",
            "Step 12700/15000 , Loss : 0.2296  \n",
            "Step 12800/15000 , Loss : 0.0087  \n",
            "Step 12900/15000 , Loss : 0.0092  \n",
            "Step 13000/15000 , Loss : 0.0029  \n",
            "Step 13100/15000 , Loss : 0.0004  \n",
            "Step 13200/15000 , Loss : 0.4009  \n",
            "Step 13300/15000 , Loss : 0.0220  \n",
            "Step 13400/15000 , Loss : 0.0004  \n",
            "Step 13500/15000 , Loss : 1.3364  \n",
            "Step 13600/15000 , Loss : 1.9977  \n",
            "Step 13700/15000 , Loss : 0.0002  \n",
            "Step 13800/15000 , Loss : 0.0103  \n",
            "Step 13900/15000 , Loss : 0.0066  \n",
            "Step 14000/15000 , Loss : 0.2010  \n",
            "Step 14100/15000 , Loss : 0.0000  \n",
            "Step 14200/15000 , Loss : 0.0062  \n",
            "Step 14300/15000 , Loss : 0.0467  \n",
            "Step 14400/15000 , Loss : 0.0000  \n",
            "Step 14500/15000 , Loss : 0.4004  \n",
            "Step 14600/15000 , Loss : 0.0006  \n",
            "Step 14700/15000 , Loss : 0.0060  \n",
            "Step 14800/15000 , Loss : 0.0001  \n",
            "Step 14900/15000 , Loss : 0.0024  \n",
            "Step 15000/15000 , Loss : 0.0007  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "2BFZo6Au4ue1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "\n",
        "class_labels = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images,labels in (test_loader):\n",
        "    images = images.reshape(-1,28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    # max returns (value ,index)\n",
        "    value, index = torch.max(outputs.data,1)  # outputs.data  : .data remove grad graph, and its for more than one element data(unlike .item())\n",
        "    \n"
      ],
      "metadata": {
        "id": "scaZtJMo4oAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}